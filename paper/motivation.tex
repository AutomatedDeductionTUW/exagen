Amid the COVID-19 pandemic, higher education has moved to distance
teaching. While online lecturing was relatively fast to implement via
webinars, recording,  streaming and online communication channels,
coming up with best practices to assess course performances was far
from trivial. Even with very sophisticated technical infrastructure,
which on the other hand is unethical to aspect from course
participants,  avoiding collaborative course work in a virtual
environment is very hard to achieve, if possible at all.
In addition, course assessment is very diverse and depends on the
available resources institutions have to implement individual oral
exams or large-scale written exams.

In this short paper we report on our solution for organizing online
written exams, where solutions to written exams require rigorous
logical reasoning and proofs rather than using mechanized test grids.
In particular, we were faced with the challenge of organizing online
written exams for our master's level course ``Automated
Deduction'' in logic and computation at TU
Wien\footnote{https://tiss.tuwien.ac.at/course/courseDetails.xhtml?dswid=2002\&dsrid=601\&courseNr=184774\&semester=2020S}.
This course introduces algorithmic techniques and fundamental results
in automated reasoning, by focusing on specialised algorithms for
reasoning in various fragments of first-order logics, such as
propositional logic, combination of ground theories, and full
first-order logic with equality.
As such, topics of the course cover from theoretical and practical
aspects of SAT/SMT solving~\cite{DPLLTinelli,NelsonOppen} and first-order theorem proving using
superposition reasoning~\cite{Ganzinger02,Rubio02,Vampire13}

We claim by no means that the framework we developed for online
examinaion is optimal.
is actually very specific to the logo
Given the time constraints of examination periods, we aimed for an
online exam setting that (i) reduces collaborative work but (ii)
requires the same workload on each participants.
The algorithmic and rigorous reasoning developed within our
course called for exam sheets focused on problem solving and deductive
proofs; as such exam sheets using test grids are not a viable solution
for written exams within our course.
We have therefore used the automated reasoning approaches introduced in our
course to automate the generation of individual exam sheets for
students enrolled in our course, by making sure that the exam tasks
remain the same in each exam sheet. 
While our proposal is very specific to the formal aspects of automated
reasonig, we believe our framework can be extended with further
constraints to scale it to other courses in formal methods. 


We believe the toolchain of automated reasoning tools we have developed for
holding online written exams could be beneficial not only for other
distance learning platforms, but also to researchers in automated
reasoning, by providing our community with a large set of randomly generated benchmarks in SAT/SMT solving and first-order theorem proving.


