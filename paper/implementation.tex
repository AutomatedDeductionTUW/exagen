We implemented our approach to randomly generating
SAT, SMT, and non-ground first-order problems in Haskell, whereas
our ground superposition problem generator was implemented in
Python. All together, our toolchain involved about 2\,300 lines of code,
including additional scripts for putting parts together.
% -------------------------------------------------------------------------------
% Language                     files          blank        comment           code
% -------------------------------------------------------------------------------
% Haskell                         18            700            407           1988
% TeX                            215             42           1011           1024
% Python                           4             41             29            251
% zsh                              2             22             14             43
% -------------------------------------------------------------------------------
% SUM:                           239            805           1461           3306
% RELEVANT FOR US: 1988 + 251 + 43 = 2282
% -------------------------------------------------------------------------------
% The implementation of formulas and terms as inductive data types
%in combination with pattern matching has been very convenient to work with.
%An interesting aspect of
%Our random generators are generic over the evaluation method of choice points.
%This allowed us to use the same code both for random sampling (to generate exams)
%and for enumerating the sample space (to check whether it is sufficiently large).
We encoded each randomly generated SMT and first-order formula into
%%% (NOTE: didn't use any external solvers for the SAT part)
the SMT-LIB input format~\cite{barrett2017smtlib} and, for sanity checks, ran the SMT
solver Z3~\cite{Z3}  and the first-order theorem prover
Vampire~\cite{Vampire13} for proving the respective formulas.
In addition, each formula has been converted  to \LaTeX{}, yielding
randomly generated exam sheets -- one such exam sheet is given in
Figure~\ref{fig:exam}.
\todo{Maybe explain the implementation in more detail?}

Regarding the filtering of generated formulas using the constraints discussed in Section~\ref{sec:satfo},
we did not require very efficient algorithms since the formulas under consideration are very small.
For example, for the restriction on the number of models we used a naive satisfiability test
based on evaluating the formula under each possible interpretation.
Thanks to this approach it is easy to add new filters/constraints.
% An advantage of this is that the addition of new filters/constraints is relatively easy.


%problem generation Our implementation consists of various programs that are tied together by a control script.
%The control script calls all problem generators
%and compiles the exam sheets, resulting in $n$ different exams in PDF format.
%
%The exam sheet template is a \LaTeX{} file
%where the concrete formulas and signatures
%have been replaced by the problem instances generated as described
%in Sections~\ref{sec:satfo}-\ref{sec: smtqf}.%``\textbackslash{}input'' commands.
%
%The ground superposition problem generator was implemented in Python,
%and utilizes a simple iteration over cartesian product of symbols
%with filtering.
%
%The SAT, SMT and redundancy problem generators have been implemented in Haskell.
%The implementation of formulas and terms as inductive data types
%in combination with pattern matching has been very convenient to work with.
%An interesting aspect of our implementation is that
%our generators are generic over the evaluation method of choice points.
%This allowed us to use the same code both for random sampling (to generate exams)
%and for enumerating the sample space (to check whether it is sufficiently large).


For the random problem generation setting of Section~\ref{sec:satfo},
we applied design principles of the Haskell library
QuickCheck~\cite{ClaessenHughes:2000:QuickCheck}.
With QuickCheck, randomly generated data can easily be defined in an embedded generator language.
However, because of our many filtering criteria, we wanted the generator to additionally support backtracking.
We were also interested in determining the size of the filtered sample space.
To this end,
we created a simple typeclass \texttt{MonadChoose} in the style of the monad transformer library (mtl),
with a single primitive operation \texttt{choose} for choosing an element from a list of possible choices:
\lstset{
    language=Haskell,
    basicstyle=\small\ttfamily,
    deletekeywords={MonadPlus,filter,length},
    columns=fixed,
}
\begin{lstlisting}
class MonadPlus m => MonadChoose m where
  choose :: [a] -> m a
\end{lstlisting}

Our generator implementations are generic over the monad, constrained by \texttt{MonadChoose}.
The following listing shows (a slightly simplified) part of the inference generator
discussed in Section~\ref{sec:fo}.
\begin{lstlisting}
genExamInference :: MonadChoose m => m Inference
genExamInference = do
  -- Define signature (partially omitted)
  let vars = ["x", "y", "z"]
  let opts = GenOptions{ vars = vars, ... }

  -- Choose variables to appear in l1 and l2
  v1 <- choose vars
  v2 <- choose (filter (/= v1) vars)

  -- Generate literals
  -- l1: exactly one occurrence of v1
  l1 <- mfilter ((==1) . length . toListOf variables)
        $ genUninterpretedLiteral opts{ vars = [v1] }
  -- l2: at least two occurrences of v2
  l2 <- mfilter ((>=2) . length . toListOf variables)
        $ genEqualityLiteral opts{ vars = [v2] }
  -- l3: ground literal
  l3 <- genUninterpretedLiteral opts{ vars = [] }

  -- (rest omitted)
  return inference

genEqualityLiteral, genUninterpretedLiteral
  :: MonadChoose m => GenOptions -> m Literal
-- (literal generators omitted)
\end{lstlisting}

We used two concrete implementations to evaluate generators:
\begin{enumerate}
    \item
        \texttt{RandomChoice}, a monad that implements \texttt{choose}
        as uniform random choice with backtracking support.
        Conceptually, this is like the standard list monad
        where \texttt{choose} works like the regular monadic bind for lists
        except that it first shuffles the list with a random permutation.
        This evaluation method is used to generate random exams.
    \item
        The standard list monad to enumerate the sample space.
        This second evaluation method helps verifying that the sample space is sufficiently large.
\end{enumerate}
